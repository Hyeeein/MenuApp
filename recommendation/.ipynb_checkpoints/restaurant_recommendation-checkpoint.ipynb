{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\[졸작] 캡스톤디자인(2)\\recommendation\n"
     ]
    }
   ],
   "source": [
    "cd D:\\[졸작] 캡스톤디자인(2)\\recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index_id            name           address  phone_number  \\\n",
      "0         0             키사스   인천 연수구 송도동 12-8  032-672-2782   \n",
      "1         1    일품양평해장국 인천대점     인천 연수구 송도동 13  032-214-0359   \n",
      "2         2       스노우폭스 송도점  인천 연수구 송도동 13-58  032-710-6464   \n",
      "3         3     오백국수 송도인천대점  인천 연수구 송도동 13-58  032-859-7788   \n",
      "4         4  맘스터치 인천대제3기숙사점   인천 연수구 송도동 12-1  032-858-3211   \n",
      "\n",
      "              category_name  restaurant_id  \\\n",
      "0        음식점 > 술집 > 호프,요리주점      254068984   \n",
      "1  음식점 > 한식 > 해장국 > 일품양평해장국      945337337   \n",
      "2           음식점 > 일식 > 초밥,롤     2127869213   \n",
      "3             음식점 > 한식 > 국수      111989094   \n",
      "4        음식점 > 패스트푸드 > 맘스터치      355891575   \n",
      "\n",
      "                               place_url  Unnamed: 7  Unnamed: 8  Unnamed: 9  \\\n",
      "0   http://place.map.kakao.com/254068984         NaN         NaN         NaN   \n",
      "1   http://place.map.kakao.com/945337337         NaN         NaN         NaN   \n",
      "2  http://place.map.kakao.com/2127869213         NaN         NaN         NaN   \n",
      "3   http://place.map.kakao.com/111989094         NaN         NaN         NaN   \n",
      "4   http://place.map.kakao.com/355891575         NaN         NaN         NaN   \n",
      "\n",
      "   Unnamed: 10  Unnamed: 11  Unnamed: 12               Unnamed: 13  \n",
      "0          NaN          NaN          NaN                       NaN  \n",
      "1          NaN          NaN          NaN                       NaN  \n",
      "2          NaN          NaN          NaN     쉐푸드, 고집, 멜팅그릴, 포썸, 팔뚝  \n",
      "3          NaN          NaN          NaN  학식 변동없는 음식 : 국밥, 치킨, 떡볶이  \n",
      "4          NaN          NaN          NaN                       NaN  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data collection/restaurant_db.csv\", encoding='cp949')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name             category_name  restaurant_id\n",
      "0             키사스        음식점 > 술집 > 호프,요리주점      254068984\n",
      "1    일품양평해장국 인천대점  음식점 > 한식 > 해장국 > 일품양평해장국      945337337\n",
      "2       스노우폭스 송도점           음식점 > 일식 > 초밥,롤     2127869213\n",
      "3     오백국수 송도인천대점             음식점 > 한식 > 국수      111989094\n",
      "4  맘스터치 인천대제3기숙사점        음식점 > 패스트푸드 > 맘스터치      355891575\n"
     ]
    }
   ],
   "source": [
    "data = data[['name', 'category_name', 'restaurant_id']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "category_name을 type 데이터로 정제 (음식점 이후 내용을 키워드로 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name             category_name  restaurant_id                type\n",
      "0             키사스        음식점 > 술집 > 호프,요리주점      254068984       [술집, 호프,요리주점]\n",
      "1    일품양평해장국 인천대점  음식점 > 한식 > 해장국 > 일품양평해장국      945337337  [한식, 해장국, 일품양평해장국]\n",
      "2       스노우폭스 송도점           음식점 > 일식 > 초밥,롤     2127869213          [일식, 초밥,롤]\n",
      "3     오백국수 송도인천대점             음식점 > 한식 > 국수      111989094            [한식, 국수]\n",
      "4  맘스터치 인천대제3기숙사점        음식점 > 패스트푸드 > 맘스터치      355891575       [패스트푸드, 맘스터치]\n"
     ]
    }
   ],
   "source": [
    "type_list = []  # type 데이터 저장할 컬럼 추가\n",
    "\n",
    "for i in data['category_name']:\n",
    "    type = i.split('>')\n",
    "    type_num = len(type)\n",
    "    \n",
    "    for j in range(type_num):\n",
    "        type[j] = type[j].strip(' ')  # 앞뒤 공백 제거\n",
    "        \n",
    "    type = type[1:]  # '음식점' 문자열 제거 후 다시 저장\n",
    "    type_list.append(type)\n",
    "\n",
    "data['type'] = type_list\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name             0\n",
      "category_name    0\n",
      "restaurant_id    0\n",
      "type             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name                type\n",
      "0             키사스       [술집, 호프,요리주점]\n",
      "1    일품양평해장국 인천대점  [한식, 해장국, 일품양평해장국]\n",
      "2       스노우폭스 송도점          [일식, 초밥,롤]\n",
      "3     오백국수 송도인천대점            [한식, 국수]\n",
      "4  맘스터치 인천대제3기숙사점       [패스트푸드, 맘스터치]\n"
     ]
    }
   ],
   "source": [
    "data = data[['name', 'type']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m feature \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      2\u001b[0m rest \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mTfidfVectorizer(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mfeature)\n\u001b[1;32m----> 3\u001b[0m rest_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mrest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(rest_matrix)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2077\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2058\u001b[0m \u001b[38;5;124;03m\"\"\"Learn vocabulary and idf, return document-term matrix.\u001b[39;00m\n\u001b[0;32m   2059\u001b[0m \n\u001b[0;32m   2060\u001b[0m \u001b[38;5;124;03mThis is equivalent to fit followed by transform, but more efficiently\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2076\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m-> 2077\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2079\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2080\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1330\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1322\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1323\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1324\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1325\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1326\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1327\u001b[0m             )\n\u001b[0;32m   1328\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1330\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1333\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1201\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1200\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1201\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1202\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1203\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:113\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    115\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:71\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[1;32m---> 71\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "feature = data['type'].tolist()\n",
    "rest = text.TfidfVectorizer(input=feature)\n",
    "rest_matrix = rest.fit_transform(feature)\n",
    "similarity = cosine_similarity(rest_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2473b9a2fa72a89b7cb01eeaf22720158ae3a74f5d679d7a459ffd3919ec650"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
